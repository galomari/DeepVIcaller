2024-06-02 20:13:57.656235: W 
Epoch 1/50
1/1 ━━━━━━━━━━━━━━━━━━━━ 5s 5s/step - accuracy: 0.4444 - loss: 0.6930 - val_accuracy: 0.8000 - val_loss: 0.6870
Epoch 2/50
1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 527ms/step - accuracy: 0.5833 - loss: 0.6914 - val_accuracy: 0.8000 - val_loss: 0.6767
Epoch 3/50
1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 563ms/step - accuracy: 0.5833 - loss: 0.6874 - val_accuracy: 0.8000 - val_loss: 0.6603
Epoch 4/50
1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 548ms/step - accuracy: 0.5833 - loss: 0.6847 - val_accuracy: 0.8000 - val_loss: 0.6287
Epoch 5/50
1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 551ms/step - accuracy: 0.5833 - loss: 0.6799 - val_accuracy: 0.8000 - val_loss: 0.6033
Epoch 6/50
1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 524ms/step - accuracy: 0.5833 - loss: 0.6718 - val_accuracy: 0.8000 - val_loss: 0.5451
Epoch 7/50
1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 561ms/step - accuracy: 0.5833 - loss: 0.6899 - val_accuracy: 0.8000 - val_loss: 0.6402
Epoch 8/50
1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 549ms/step - accuracy: 0.5833 - loss: 0.6779 - val_accuracy: 0.8000 - val_loss: 0.6301
Epoch 9/50
1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 516ms/step - accuracy: 0.5833 - loss: 0.6780 - val_accuracy: 0.8000 - val_loss: 0.6217
Epoch 10/50
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 471ms/step - accuracy: 0.5833 - loss: 0.6731 - val_accuracy: 0.8000 - val_loss: 0.6020
Epoch 11/50
1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 505ms/step - accuracy: 0.5833 - loss: 0.6639 - val_accuracy: 0.8000 - val_loss: 0.5620
Epoch 12/50
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 481ms/step - accuracy: 0.5833 - loss: 0.6668 - val_accuracy: 0.8000 - val_loss: 0.5737
Epoch 13/50
1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 635ms/step - accuracy: 0.5833 - loss: 0.6622 - val_accuracy: 0.8000 - val_loss: 0.5675
Epoch 14/50
1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 722ms/step - accuracy: 0.5833 - loss: 0.6542 - val_accuracy: 0.8000 - val_loss: 0.5462
Epoch 15/50
1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 697ms/step - accuracy: 0.5833 - loss: 0.6813 - val_accuracy: 0.8000 - val_loss: 0.6397
Epoch 16/50
1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 689ms/step - accuracy: 0.5833 - loss: 0.6728 - val_accuracy: 0.8000 - val_loss: 0.6227
/home/galomari/.local/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable 
  saveable.load_own_variables(weights_store.get(inner_path))
  Total params: 153,732 (600.52 KB)
 Trainable params: 153,732 (600.52 KB)
 Non-trainable params: 0 (0.00 B)
Predicting...
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 230ms/step
2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 459ms/step - accuracy: 0.5556 - loss: 0.6714
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 124ms/step - accuracy: 0.6486 - loss: 0.6511
-------vicaller_fastq_test_result------------------
vicaller_fastq_Test_pos_Quantity: 4
vicaller_fastq_Test_neg_Quantity: 5
Test acc: 0.5555555820465088
Test loss: 0.6714482307434082
auroc: 0.95
aupr: 0.9666666666666668
-------vicaller_bam_test_result------------------
vicaller_bam_Test_pos_Quantity: 13
vicaller_bam_Test_neg_Quantity: 24
Test acc: 0.6486486196517944
Test loss: 0.6510680317878723
auroc: 0.8125
aupr: 0.8679118059912855
Explanation of Results
The results shown are from training and evaluating a deep learning model designed for identifying viral integration events using both FASTQ and BAM files. Let's break down the key parts of the output and what they mean:
Training Phase
•	Epoch 1/50 to Epoch 16/50: These lines show the progress of training the model over 50 epochs. For each epoch, we see:
o	Accuracy: The accuracy of the model on the training set during that epoch.
o	Loss: The loss value on the training set.
o	Val Accuracy: The accuracy of the model on the validation set.
o	Val Loss: The loss value on the validation set.
The metrics indicate that the model starts to learn and improve its performance over the epochs.
Model Summary
•	Model Structure: A detailed summary of the model's architecture is displayed, including the layers used, their output shapes, and the number of parameters. This is useful for understanding the complexity and structure of the model.
Testing Phase
•	Predicting...: Indicates that the model is making predictions on the test data.
•	Test Results:
o	Accuracy: The proportion of correct predictions out of all predictions.
o	Loss: A measure of the model's performance; lower loss generally indicates better performance.
o	AUROC (Area Under the Receiver Operating Characteristic Curve): A measure of the model's ability to distinguish between classes. A higher value indicates better performance.
o	AUPR (Area Under the Precision-Recall Curve): Similar to AUROC, but focuses on the trade-off between precision and recall. Higher values indicate better performance in handling imbalanced classes.
For the FASTQ test set:
•	Test Accuracy: 0.556
•	Test Loss: 0.671
•	AUROC: 0.95
•	AUPR: 0.967
For the BAM test set:
•	Test Accuracy: 0.649
•	Test Loss: 0.651
•	AUROC: 0.813
•	AUPR: 0.868
How This Improves VIcaller
1.	Enhanced Model Training: By using deep learning techniques, the model can potentially learn more complex patterns in the data compared to traditional methods used in VIcaller.
2.	Use of Attention Mechanism: The addition of an attention layer allows the model to focus on the most relevant parts of the sequences, potentially leading to more accurate predictions.
3.	Evaluation Metrics: The use of comprehensive metrics like AUROC and AUPR provides a deeper understanding of the model's performance, especially in imbalanced datasets.
4.	Modular Approach: The separation of data processing and model training/testing into different scripts (DeepCaller.py and the data processing script) makes the workflow more organized and easier to maintain.
Steps to Follow
1.	Ensure Data Preparation: Make sure your FASTQ and BAM files are properly processed into one-hot encoded matrices using the provided data processing script.
2.	Directory Setup: Ensure the necessary directories (Model, Test_Result/vicaller_fastq_Result, and Test_Result/vicaller_bam_Result) are created before running the model training script.
3.	Run Data Processing: Execute the data processing script to generate the necessary .npy files.
4.	Train and Evaluate the Model: Execute the DeepCaller.py script to train and evaluate the model. Monitor the training process and evaluate the results to ensure the model is learning effectively.
By following these steps and using the improved deep learning model, VIcaller can achieve better accuracy and reliability in detecting viral integration events, thus enhancing its overall performance and utility.


